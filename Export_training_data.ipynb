{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OEo726hQb_ij"
      },
      "source": [
        "# Setup\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "V3aXlWq5bs3d",
        "outputId": "61d6c68e-ff9c-41cc-a49a-7d42f4c345bc"
      },
      "outputs": [],
      "source": [
        "import ee\n",
        "import urllib.request\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from matplotlib.patches import Polygon\n",
        "import PIL\n",
        "from PIL import Image, ImageDraw\n",
        "from osgeo import gdal\n",
        "from osgeo import osr\n",
        "import numpy as np\n",
        "import os, sys\n",
        "import random\n",
        "import shutil\n",
        "import pandas as pd\n",
        "\n",
        "ee.Authenticate()\n",
        "ee.Initialize()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bcVQSDPeCMGQ"
      },
      "source": [
        "# Sentinel 2 CSV List Export\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_dNuOxiVDxTi",
        "outputId": "e6dee285-543c-4dca-b757-6399876c9d93"
      },
      "outputs": [],
      "source": [
        "#Point to the location of your CSV with the locations you would like to export\n",
        "#The default points to a file called \"random_points\" that you can drop on the right\n",
        "locations = pd.read_csv('file_name.csv', sep='\\t')\n",
        "locations = locations.rename(columns={'x': 'X', 'y': 'Y', 'Unnamed: 0':'id'})\n",
        "print(locations)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4lsiFMcHB1kS"
      },
      "outputs": [],
      "source": [
        "#Point to the location of your CSV with the locations you would like to export\n",
        "#The default points to a file called \"random_points\" that you can drop on the right\n",
        "a_large_mw_locations = pd.read_csv('a_and_large_mw.csv', sep=',')\n",
        "a_large_mw_locations = a_large_mw_locations.columns.tolist()\n",
        "a_large_mw_locations = [int(location) for location in a_large_mw_locations]\n",
        "a_large_mw_locations"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 55,
      "metadata": {
        "id": "vvjyULUYCxs2"
      },
      "outputs": [],
      "source": [
        "# export settings\n",
        "only_export_large_locations = True\n",
        "export_path = \"a_large_sentinel_export\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Variety of Configuations\n",
        "vis_min = 0  #Visualization settings for the thumbnail\n",
        "vis_max = 1024 #Visualization settings for the thumbnail\n",
        "vis_bands = ['B4', 'B3', 'B2'] #Includes the bands for RGB\n",
        "imageDimensions = '512x512' #Set thumbnail image size (can't be too big, or you run into problems)\n",
        "nir_bands = ['B8'] #Includes the bands for nir\n",
        "swirB11_bands = ['B11'] #Includes the bands for swir B11\n",
        "swirB12_bands = ['B12'] #Includes the bands for swir B11\n",
        "#0\n",
        "startLocation = 4429\n",
        "last_id=-1\n",
        "for index, row in locations.iloc[0:].iterrows():\n",
        " #skip\n",
        "  if int(row['id'])<startLocation or last_id==int(row['id']) or (only_export_large_locations and int(row['id']) not in a_large_mw_locations):\n",
        "    continue\n",
        "  last_id=int(row['id'])\n",
        "  print(last_id)\n",
        "\n",
        "  #Choose your location to request an image from\n",
        "  longitude = row['X']\n",
        "  latitude = row['Y']\n",
        "  id = row['id']\n",
        "\n",
        "  center = ee.Geometry.Point(longitude,latitude)\n",
        "  # Import Sentinel dataset\n",
        "  s2 = (ee.ImageCollection(\"COPERNICUS/S2_SR\")\n",
        "    .filterBounds(center)\n",
        "    .sort('CLOUDY_PIXEL_PERCENTAGE')\n",
        "    .filterDate('2018-01-01', '2018-12-30')\n",
        "    .first()\n",
        "  )\n",
        "  # Working, but with getInfo(), which makes the code a bit slower\n",
        "  try:\n",
        "    global sentinel_footprint\n",
        "    sentinel_footprint = (ee.Geometry.Polygon((s2.getInfo().get('properties').get('system:footprint').get('coordinates'))))\n",
        "  except:\n",
        "    print(\"No Footprint found\")\n",
        "    break\n",
        "    continue\n",
        "  footprint = (ee.Geometry.Polygon((s2.getInfo().get('properties').get('system:footprint').get('coordinates'))))\n",
        "\n",
        "  sentinel_centroid = center\n",
        "  # Create a rectangular export area\n",
        "  exportAreaSmall = (sentinel_centroid.buffer(2530).bounds());\n",
        "\n",
        "  if sentinel_footprint.contains(exportAreaSmall,1).getInfo() == True:\n",
        "    exportArea = exportAreaSmall\n",
        "  else:\n",
        "    print(\"No fit\")\n",
        "    continue\n",
        "\n",
        "# save rgb\n",
        "  s2Vis = {\n",
        "      'region': exportArea,\n",
        "      'crs': (s2.select('B4').projection()),\n",
        "      'dimensions': imageDimensions,\n",
        "      'format': 'jpg',\n",
        "      'min': vis_min,\n",
        "      'max': vis_max,\n",
        "      'bands': vis_bands\n",
        "  }\n",
        "\n",
        "  s2_url = (s2.getThumbURL(s2Vis))\n",
        "\n",
        "  #Change the location where the images are saved by replacing \"content\" with the location in your Google Drive\n",
        "  s2_name = \"{}/preview/S2_{}_{}_{}.jpg\".format(export_path,id,longitude,latitude)\n",
        "  # save\n",
        "  urllib.request.urlretrieve(s2_url, s2_name)\n",
        "\n",
        "  # find min and max of df\n",
        "  x_min = min(pd.DataFrame(exportArea.getInfo().get('coordinates')[0], columns = ['x', 'y'])['x'])\n",
        "  y_min = min(pd.DataFrame(exportArea.getInfo().get('coordinates')[0], columns = ['x', 'y'])['y'])\n",
        "  x_max = max(pd.DataFrame(exportArea.getInfo().get('coordinates')[0], columns = ['x', 'y'])['x'])\n",
        "  y_max = max(pd.DataFrame(exportArea.getInfo().get('coordinates')[0], columns = ['x', 'y'])['y'])\n",
        "\n",
        "  # generate a tif file with all bands!\n",
        "  s2_tif_name = \"S2_tif_{}_{}_{}_merged\".format(id,longitude,latitude)\n",
        "\n",
        "  _region = ee.Geometry.BBox(x_min, y_min, x_max, y_max);\n",
        "  task = ee.batch.Export.image.toDrive(\n",
        "      image = s2.select('B2','B3','B4','B8','B11','B12'),\n",
        "      description=s2_tif_name,\n",
        "      folder='large_tif_files',\n",
        "      region=_region,\n",
        "      dimensions=imageDimensions,\n",
        "      crs=(s2.select('B4').projection())\n",
        "  )\n",
        "  task.start()\n",
        "\n",
        "  # generate mask\n",
        "  _locations = locations.loc[(locations['id']==last_id)]\n",
        "\n",
        "  # Define the dimensions of the image\n",
        "  width = 512\n",
        "  height = 512\n",
        "\n",
        "  # Create a new black image\n",
        "  img = Image.new(\"RGB\", (width, height), \"black\")\n",
        "  # draw main one\n",
        "  draw = ImageDraw.Draw(img)\n",
        "  # (0 2024) (2024 2024)\n",
        "  # (0 0) (2024 0)\n",
        "\n",
        "  one_x_px_in_degree = (x_max-x_min)/width\n",
        "  one_y_px_in_degree = (y_max-y_min)/height\n",
        "\n",
        "  # Define the coordinates of the polygon\n",
        "  polygon_coords = list(_locations[[\"X\",\"Y\"]].to_records(index=False))\n",
        "  export_coords = []\n",
        "  for coord in polygon_coords:\n",
        "    x,y = coord\n",
        "    x = (x-x_min)/one_x_px_in_degree\n",
        "    y = (y-y_min)/one_y_px_in_degree\n",
        "    export_coords.append((x,y))\n",
        "    if len(export_coords)>2:\n",
        "      draw.polygon(export_coords, fill=\"white\")\n",
        "\n",
        "  # calculate how much lookback and lookforward is possible\n",
        "  lookback = 700\n",
        "  if last_id<lookback:\n",
        "    lookback=0\n",
        "    \n",
        "  lookforward = 700\n",
        "\n",
        "  # check before and after to see if there are more solar panels in the picture!\n",
        "  for near_locations in range(last_id-lookback,last_id):\n",
        "    export_coords = []\n",
        "    polygon_coords = list(locations.loc[(locations['id']==near_locations)][[\"X\",\"Y\"]].to_records(index=False))\n",
        "    for coord in polygon_coords:\n",
        "      x,y = coord\n",
        "      if x > x_min and x < x_max and y > y_min and y < y_max:\n",
        "        x = (x-x_min)/one_x_px_in_degree\n",
        "        y = (y-y_min)/one_y_px_in_degree\n",
        "        export_coords.append((x,y))\n",
        "    if len(export_coords)>3:\n",
        "        draw.polygon(export_coords, fill=\"white\")\n",
        "  for near_locations in range(last_id+1,last_id+lookforward):\n",
        "    export_coords = []\n",
        "    polygon_coords = list(locations.loc[(locations['id']==near_locations)][[\"X\",\"Y\"]].to_records(index=False))\n",
        "    for coord in polygon_coords:\n",
        "      x,y = coord\n",
        "      if x > x_min and x < x_max and y > y_min and y < y_max:\n",
        "        x = (x-x_min)/one_x_px_in_degree\n",
        "        y = (y-y_min)/one_y_px_in_degree\n",
        "        export_coords.append((x,y))\n",
        "    if len(export_coords)>3:\n",
        "        draw.polygon(export_coords, fill=\"white\")\n",
        "  # Draw the white polygon on the black image\n",
        "  # Save the image as a JPEG\n",
        "  #flip because of wrong coordinate system\n",
        "  plt.axis('off')\n",
        "  plt.imshow(img, origin=\"lower\", extent=(0, width, 0, height))\n",
        "  plt.savefig('{}/masks/S2_{}_{}_{}.jpg'.format(export_path,id,longitude,latitude),dpi=500, bbox_inches='tight', transparent=True, pad_inches=0)\n",
        "  # since we only created mask preview files so far, lets also create the matching geotif files!\n",
        "  # resize mask to match 512 dimensions of tif image!\n",
        "\n",
        "  im = Image.open('{}/masks/S2_{}_{}_{}.jpg'.format(export_path,id,longitude,latitude))\n",
        "  maxsize = (width, height)\n",
        "  im.thumbnail(maxsize, Image.Resampling.LANCZOS)\n",
        "  im.save('{}/masks/S2_{}_{}_{}.jpg'.format(export_path,id,longitude,latitude))\n",
        "  # since mask is based on different res than 512 (which is the output), so we need to rescale!\n",
        "  arr = np.array(im)\n",
        "  #  Choose some Geographic Transform\n",
        "  lat = [x_min,x_max]\n",
        "  lon = [y_min,y_max]\n",
        "\n",
        "  # set geotransform\n",
        "  nx = 512\n",
        "  ny = 512\n",
        "  xmin, ymin, xmax, ymax = [min(lon), min(lat), max(lon), max(lat)]\n",
        "  xres = (xmax - xmin) / float(nx)\n",
        "  yres = (ymax - ymin) / float(ny)\n",
        "  geotransform = (xmin, xres, 0, ymax, 0, -yres)\n",
        "\n",
        "  mask_pixels = np.zeros((nx,ny), dtype=np.uint8)\n",
        "\n",
        "  for x in range(0,nx):\n",
        "      for y in range(0,ny):\n",
        "        if arr[y][x][0]!= 0:\n",
        "         mask_pixels[y,x] = 1\n",
        "        else:\n",
        "          mask_pixels[y,x] = 0\n",
        "\n",
        "  # create the raster file\n",
        "  dst_ds = gdal.GetDriverByName('GTiff').Create('{}/tif_masks/S2_{}_{}_{}.tif'.format(export_path,id,longitude,latitude), ny, nx, 1, gdal.GDT_Byte)\n",
        "\n",
        "  dst_ds.SetGeoTransform(geotransform)    # specify coords\n",
        "  srs = osr.SpatialReference()            # establish encoding\n",
        "  srs.ImportFromEPSG(32632)                # WGS84 lat/long\n",
        "  dst_ds.SetProjection(srs.ExportToWkt()) # export coords to file\n",
        "  dst_ds.GetRasterBand(1).WriteArray(mask_pixels)   # write r-band to the raster\n",
        "  dst_ds.FlushCache()                     # write to disk\n",
        "  dst_ds = None"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ibjISvkNVACR"
      },
      "outputs": [],
      "source": [
        "# check epsg nrw\n",
        "s2.select('B4').projection().getInfo()[\"crs\"]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rGBuXaFsy8wu",
        "outputId": "8d09bcc4-d2e9-4f1b-d8f0-d7ef04feacf4"
      },
      "outputs": [],
      "source": [
        "# This is for updating the mask to different values!\n",
        "vis_min = 0  #Visualization settings for the thumbnail\n",
        "vis_max = 1024 #Visualization settings for the thumbnail\n",
        "vis_bands = ['B4', 'B3', 'B2'] #Includes the bands for RGB\n",
        "imageDimensions = '512x512' #Set thumbnail image size (can't be too big, or you run into problems)\n",
        "nir_bands = ['B8'] #Includes the bands for nir\n",
        "swirB11_bands = ['B11'] #Includes the bands for swir B11\n",
        "swirB12_bands = ['B12'] #Includes the bands for swir B11\n",
        "\n",
        "startLocation = 0\n",
        "last_id=-1\n",
        "for index, row in locations.iloc[0:].iterrows():\n",
        " #skip\n",
        "  if int(row['id'])<startLocation or last_id==int(row['id']):\n",
        "    continue\n",
        "\n",
        "  print(last_id)\n",
        "  last_id=int(row['id'])\n",
        "  #Choose your location to request an image from\n",
        "  longitude = row['X']\n",
        "  latitude = row['Y']\n",
        "  id = row['id']\n",
        "\n",
        "  file = '{}/tif_masks/S2_{}_{}_{}.tif'.format(export_path,id,longitude,latitude)\n",
        "  ds = gdal.Open(file)\n",
        "  if not ds:\n",
        "    continue\n",
        "  band = ds.GetRasterBand(1)\n",
        "  arr = band.ReadAsArray()\n",
        "  [rows, cols] = arr.shape\n",
        "  arr_min = arr.min()\n",
        "  arr_max = arr.max()\n",
        "  arr_mean = int(arr.mean())\n",
        "  arr_out = np.where((arr < 1), 0, arr)\n",
        "  arr_out = np.where((arr_out >= 1), 1, arr_out)\n",
        "  driver = gdal.GetDriverByName(\"GTiff\")\n",
        "  outdata = driver.Create('{}/tif_masks/S2_{}_{}_{}.tif'.format(export_path,id,longitude,latitude), cols, rows, 1, gdal.GDT_Byte)\n",
        "  outdata.SetGeoTransform(ds.GetGeoTransform())##sets same geotransform as input\n",
        "  outdata.SetProjection(ds.GetProjection())##sets same projection as input\n",
        "  print(arr_out.shape)\n",
        "  outdata.GetRasterBand(1).WriteArray(arr_out)\n",
        "  outdata.FlushCache() ##saves to disk!!\n",
        "  outdata = None\n",
        "  band=None\n",
        "  break"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dQCKH0GtyiER",
        "outputId": "35700f30-c6e4-4c14-bd0a-94931d7cde8d"
      },
      "outputs": [],
      "source": [
        "# for\n",
        "import random\n",
        "import shutil\n",
        "# create test/train sets of drive data for model!\n",
        "# get list of available data\n",
        "data=[entry.name for entry in os.scandir('{}/tif_files'.format(export_path)) if entry.is_file()]\n",
        "mask=[entry.name for entry in os.scandir('{}/tif_masks'.format(export_path)) if entry.is_file()]\n",
        "print(data)\n",
        "print(mask)\n",
        "# generate test/train from available data\n",
        "random.shuffle(data)\n",
        "length = int(len(data)*0.7)\n",
        "print(len(data))\n",
        "train_data = data[:length]\n",
        "test_data = data[length:]\n",
        "shutil.rmtree('validation')\n",
        "shutil.rmtree('training')\n",
        "os.mkdir(\"validation\")\n",
        "os.mkdir(\"training\")\n",
        "\n",
        "# build test and train data folders\n",
        "# copy both tif files to training or validation!\n",
        "for entry in os.scandir('{}/tif_files'.format(export_path)):\n",
        "  if entry.is_file():\n",
        "    if entry.name in train_data and (entry.name.replace(\"_merged\",\"\").replace(\"_tif\",\"\") in mask):\n",
        "      # data\n",
        "      shutil.copyfile(f'{export_path}/tif_files/{entry.name}', f'training/{entry.name}')\n",
        "      # mask\n",
        "      shutil.copyfile(f'{export_path}/tif_masks/{entry.name.replace(\"_merged\",\"\").replace(\"_tif\",\"\")}', f'training/{entry.name.replace(\"_merged\",\"_mask\")}')\n",
        "    elif entry.name in test_data and (entry.name.replace(\"_merged\",\"\").replace(\"_tif\",\"\") in mask):\n",
        "      #data\n",
        "      shutil.copyfile(f'{export_path}/tif_files/{entry.name}', f'validation/{entry.name}')\n",
        "      #mask\n",
        "      shutil.copyfile(f'{export_path}/tif_masks/{entry.name.replace(\"_merged\",\"\").replace(\"_tif\",\"\")}', f'validation/{entry.name.replace(\"_merged\",\"_mask\")}')\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "uh0zFgYvRRBa"
      },
      "outputs": [],
      "source": [
        "!zip -r /content/training.zip /content/training\n",
        "!zip -r /content/validation.zip /content/validation"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.13"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
